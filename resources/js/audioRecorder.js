/**
 * Alpine.js component to handle audio recording with system audio support and real-time transcription.
 * 
 * @param {Object} wire - The Livewire component that will receive the audio data
 * @returns {Object} - Alpine.js component data
 */
window.audioRecorder = function(wire) {
    return {
        mediaRecorder: null,
        audioChunks: [],
        isRecording: false,
        audioURL: null,
        recordingStartTime: null,
        recordingTime: '00:00',
        recordingTimer: null,
        captureSystemAudio: false,
        transcriber: null,
        isTranscriberReady: false,
        currentTranscription: '',
        processingAudio: false,
        accumulatedChunks: [],
        transcriptionInterval: null,

        /**
         * Initialize the component
         */
        async init() {
            console.log('üé§ Initializing audio recorder component...');
            try {
                if (this.transcriber) {
                    console.log('‚ö†Ô∏è Transcriber already exists, cleaning up...');
                    this.transcriber = null;
                }

                // Check WebGPU support
                const isWebGPUSupported = await WhisperTranscriber.isSupported();
                console.log('üñ•Ô∏è WebGPU support status:', isWebGPUSupported);
                if (!isWebGPUSupported) {
                    console.warn('‚ö†Ô∏è WebGPU is not supported. Real-time transcription will not be available.');
                    return;
                }

                // Initialize Whisper
                console.log('üéØ Creating Whisper transcriber instance...');
                this.transcriber = new WhisperTranscriber();
                
                // Set up callbacks before initialization
                this.transcriber.onResult((text) => {
                    console.log('üìù Received transcription result:', text);
                    if (text && typeof text === 'string') {
                        console.log('‚úçÔ∏è Updating transcription display and wire state');
                        this.currentTranscription = text;
                        if (wire && typeof wire.set === 'function') {
                            wire.set('transcription', text);
                        } else {
                            console.error('‚ùå Wire or wire.set is not available');
                        }
                    }
                });

                this.transcriber.onReady(() => {
                    console.log('‚úÖ Whisper transcriber is ready');
                    this.isTranscriberReady = true;
                });

                console.log('üöÄ Starting transcriber initialization...');
                await this.transcriber.initialize();
                console.log('‚ú® Audio recorder component initialization complete');
            } catch (error) {
                console.error('‚ùå Error initializing transcriber:', error);
                this.transcriber = null;
                this.isTranscriberReady = false;
            }
        },

        /**
         * Start recording audio
         */
        async startRecording() {
            console.log('üé¨ Starting recording process...');
            if (!this.isTranscriberReady) {
                console.error('‚ùå Cannot start recording - transcriber not ready');
                alert('Transcription system is not ready. Please try again in a moment.');
                return;
            }
            
            console.log('üìä Current state - isTranscriberReady:', this.isTranscriberReady);
            this.audioChunks = [];
            this.accumulatedChunks = [];
            this.audioURL = null;
            this.currentTranscription = '';
            
            try {
                let audioStream;
                
                if (this.captureSystemAudio) {
                    console.log('üéôÔ∏è Requesting system audio + microphone access...');
                    // Request both microphone and system audio (display media) access
                    const displayStream = await navigator.mediaDevices.getDisplayMedia({
                        video: false,
                        audio: true
                    });
                    console.log('üñ•Ô∏è System audio stream acquired');
                    
                    // Get microphone access
                    const micStream = await navigator.mediaDevices.getUserMedia({
                        audio: true,
                        video: false
                    });
                    console.log('üé§ Microphone stream acquired');
                    
                    // Combine the audio tracks from both streams
                    const audioTracks = [
                        ...displayStream.getAudioTracks(),
                        ...micStream.getAudioTracks()
                    ];
                    console.log('üîÑ Combined audio tracks:', audioTracks.length);
                    
                    // Create a new stream with all audio tracks
                    audioStream = new MediaStream(audioTracks);
                } else {
                    console.log('üé§ Requesting microphone-only access...');
                    // Just get microphone access
                    audioStream = await navigator.mediaDevices.getUserMedia({
                        audio: true,
                        video: false
                    });
                    console.log('‚úÖ Microphone stream acquired');
                }
                
                // Initialize MediaRecorder with the stream
                console.log('üìº Creating MediaRecorder...');
                this.mediaRecorder = new MediaRecorder(audioStream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                console.log('‚úÖ MediaRecorder created with settings:', this.mediaRecorder.mimeType);
                
                // Set up event handlers
                this.mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        console.log('üì¶ Received audio chunk, size:', event.data.size);
                        this.audioChunks.push(event.data);
                        this.accumulatedChunks.push(event.data);
                    }
                };
                
                this.mediaRecorder.onstop = async () => {
                    console.log('‚èπÔ∏è Recording stopped, processing final audio...');
                    try {
                        const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                        console.log('üì¶ Final audio blob size:', audioBlob.size);
                        this.audioURL = URL.createObjectURL(audioBlob);
                        
                        // Clean up tracks
                        if (this.cleanupTracks) {
                            console.log('üßπ Cleaning up audio tracks...');
                            this.cleanupTracks();
                        }
                        
                        // Stop the timer and transcription interval
                        clearInterval(this.recordingTimer);
                        clearInterval(this.transcriptionInterval);
                        this.recordingStartTime = null;

                        // Process the complete audio for final transcription
                        if (this.isTranscriberReady && this.transcriber) {
                            console.log('üéØ Processing final transcription...');
                            const transcription = await this.transcriber.transcribe(audioBlob);
                            if (transcription && typeof transcription === 'string') {
                                console.log('üìù Final transcription result:', transcription);
                                this.currentTranscription = transcription;
                                wire.set('transcription', transcription);
                            }
                        } else {
                            console.warn('‚ö†Ô∏è Cannot process final transcription - transcriber not ready');
                        }
                    } catch (error) {
                        console.error('‚ùå Error in onstop handler:', error);
                        this.errorMessage = 'Error processing audio: ' + error.message;
                    }
                };
                
                // Start recording with chunks every 3 seconds
                console.log('‚ñ∂Ô∏è Starting MediaRecorder...');
                this.mediaRecorder.start(3000);
                this.isRecording = true;
                console.log('‚úÖ Recording started');
                
                // Start the timer
                this.recordingStartTime = Date.now();
                this.recordingTimer = setInterval(() => this.updateRecordingTime(), 1000);

                // Set up periodic transcription of accumulated chunks
                if (this.isTranscriberReady && this.transcriber) {
                    console.log('‚ö° Setting up periodic transcription...');
                    this.transcriptionInterval = setInterval(async () => {
                        if (this.accumulatedChunks.length > 0 && !this.processingAudio) {
                            console.log('üîÑ Processing accumulated chunks:', this.accumulatedChunks.length);
                            this.processingAudio = true;
                            try {
                                const audioBlob = new Blob(this.accumulatedChunks, { type: 'audio/webm' });
                                console.log('üì¶ Created audio blob from chunks, size:', audioBlob.size);
                                const transcription = await this.transcriber.transcribe(audioBlob);
                                if (transcription && typeof transcription === 'string') {
                                    console.log('üìù Interim transcription result:', transcription);
                                    this.currentTranscription = transcription;
                                    wire.set('transcription', transcription);
                                }
                                // Clear accumulated chunks after successful transcription
                                this.accumulatedChunks = [];
                            } catch (error) {
                                console.error('‚ùå Error transcribing audio chunk:', error);
                            } finally {
                                this.processingAudio = false;
                            }
                        }
                    }, 5000); // Try to transcribe every 5 seconds
                } else {
                    console.warn('‚ö†Ô∏è Periodic transcription not set up - transcriber not ready');
                }
                
            } catch (error) {
                console.error('‚ùå Error starting recording:', error);
                alert('Could not start recording: ' + error.message);
            }
        },

        /**
         * Stop recording
         */
        stopRecording() {
            console.log('‚èπÔ∏è Stopping recording...');
            if (!this.mediaRecorder) {
                console.warn('‚ö†Ô∏è No active MediaRecorder found');
                return;
            }
            if (!this.isRecording) {
                console.warn('‚ö†Ô∏è Not currently recording');
                return;
            }
            try {
                this.mediaRecorder.stop();
                this.isRecording = false;
                console.log('‚úÖ Recording stopped');
            } catch (error) {
                console.error('‚ùå Error stopping recording:', error);
                // Try to clean up anyway
                this.isRecording = false;
                this.mediaRecorder = null;
            }
        },

        /**
         * Reset recording state
         */
        resetRecording() {
            console.log('üîÑ Resetting recording state...');
            this.audioChunks = [];
            this.accumulatedChunks = [];
            this.audioURL = null;
            this.currentTranscription = '';
            if (this.transcriptionInterval) {
                clearInterval(this.transcriptionInterval);
            }
            console.log('‚úÖ Recording state reset');
        },

        /**
         * Update recording time display
         */
        updateRecordingTime() {
            if (!this.recordingStartTime) return;
            
            const elapsed = Math.floor((Date.now() - this.recordingStartTime) / 1000);
            const minutes = Math.floor(elapsed / 60).toString().padStart(2, '0');
            const seconds = (elapsed % 60).toString().padStart(2, '0');
            this.recordingTime = `${minutes}:${seconds}`;
        }
    };
}; 